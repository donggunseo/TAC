{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c651c2cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10249c2d523474d84bde74308b39890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7ff2add5a04bc4b1064977389eceab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9240790d6a7e497aa979324974a708b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21fb5a53c3bc486bbbd52684de5068d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     torch_dtype=\"auto\",\n",
    "#     device_map=\"auto\"\n",
    "# )\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "# model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# generated_ids = model.generate(\n",
    "#     **model_inputs,\n",
    "#     max_new_tokens=512\n",
    "# )\n",
    "# generated_ids = [\n",
    "#     output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "# ]\n",
    "\n",
    "# response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70d661b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nGive me a short introduction to large language model.<|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e75b2915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c302ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.randn(10,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1059d08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.9837e-01, -7.0353e-01, -3.5719e-01, -1.1586e+00],\n",
       "        [ 1.7654e+00, -1.1997e+00, -4.1497e-01, -5.4547e-01],\n",
       "        [-1.0796e+00,  1.7726e+00, -1.2707e+00, -9.3302e-01],\n",
       "        [ 1.8305e+00,  2.9170e+00,  5.6828e-02,  2.5530e-01],\n",
       "        [ 1.9603e+00, -1.0589e+00, -7.8571e-02, -1.4501e-01],\n",
       "        [ 1.3621e+00,  1.8107e-01, -1.7502e-03, -1.9096e+00],\n",
       "        [-7.4161e-01,  2.2433e+00,  5.6576e-01,  6.0646e-01],\n",
       "        [ 1.1309e+00,  2.6344e-02, -6.3389e-01,  8.1797e-02],\n",
       "        [ 1.9896e+00, -3.6213e-01, -1.4316e-01, -4.1553e-01],\n",
       "        [-3.6178e-01, -5.2421e-02, -3.0385e-01, -1.0518e+00]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a004fde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5984, -0.7035, -0.3572, -1.1586],\n",
       "        [ 1.7654, -1.1997, -0.4150, -0.5455],\n",
       "        [-1.0796,  1.7726, -1.2707, -0.9330],\n",
       "        [ 1.8305,  2.9170,  0.0568,  0.2553],\n",
       "        [ 1.9603, -1.0589, -0.0786, -0.1450]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[x,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed1149a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5984, -0.7035, -0.3572, -1.1586],\n",
       "        [ 1.7654, -1.1997, -0.4150, -0.5455],\n",
       "        [-1.0796,  1.7726, -1.2707, -0.9330],\n",
       "        [ 1.8305,  2.9170,  0.0568,  0.2553],\n",
       "        [ 1.9603, -1.0589, -0.0786, -0.1450]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[[0,1,2,3,4],]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2f71d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file tokenizer.json from cache at /home/donggunseo/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B/snapshots/d04e592bb4f6aa9cfee91e2e20afa771667e1d4b/tokenizer.json\n",
      "loading file tokenizer.model from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/donggunseo/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B/snapshots/d04e592bb4f6aa9cfee91e2e20afa771667e1d4b/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/donggunseo/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B/snapshots/d04e592bb4f6aa9cfee91e2e20afa771667e1d4b/tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer \n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c14ad651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3786, 11459, 4023, 271, 128001]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.encode(\" \"+\"card_arrival\"+\"\\n\\n\"+tok.eos_token, add_special_tokens = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "929b71cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "z = [1, 2,3,4,5,6]\n",
    "\n",
    "zp = random.sample(z,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fde674a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd59ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "site",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
